<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!--  
    Document Title
    =============================================
  -->
  <title>UG2+ Challenge</title>
    <!--  
    Favicons
    =============================================
  -->
  <link rel="apple-touch-icon" sizes="57x57" href="assets/images/favicons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="assets/images/favicons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="assets/images/favicons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="assets/images/favicons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="assets/images/favicons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="assets/images/favicons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="assets/images/favicons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="assets/images/favicons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="assets/images/favicons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="assets/images/favicons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="assets/images/favicons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicons/favicon-16x16.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="assets/images/favicons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
    <!--  
    Stylesheets
    =============================================
    
  -->
  <!-- Default stylesheets-->
  <link href="assets/lib/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Template specific stylesheets-->
  <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:400,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Volkhov:400i" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet">
  <link href="assets/lib/animate.css/animate.css" rel="stylesheet">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
  <link href="assets/lib/et-line-font/et-line-font.css" rel="stylesheet">
  <link href="assets/lib/flexslider/flexslider.css" rel="stylesheet">
  <link href="assets/lib/owl.carousel/dist/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/lib/owl.carousel/dist/assets/owl.theme.default.min.css" rel="stylesheet">
  <link href="assets/lib/magnific-popup/dist/magnific-popup.css" rel="stylesheet">
  <link href="assets/lib/simple-text-rotator/simpletextrotator.css" rel="stylesheet">
  <!-- Main stylesheet and color file-->
  <link href="assets/css/style.css" rel="stylesheet">
  <link id="color-scheme" href="assets/css/colors/default.css" rel="stylesheet">
</head>
  <body data-spy="scroll" data-target=".onpage-navigation" data-offset="60">
    <a id="ddmenuLink" href="menu_transparent.html">Menu</a>
    <main>
      <div class="page-loader">
        <div class="loader">Loading...</div>
      </div>
      
      
      <div class="main">
        <section class="module bg-dark-30 portfolio-page-header" data-background="assets/images/speakersbg.jpg" style="padding: 30px 0;">
          <div class="container">
            <div class="row" style="padding-top: 40px">
              <div class="col-sm-6 col-sm-offset-3">
                <h2 class="module-title font-alt" style="margin: 0 0 20px">Program</h2>
                <h3 class="module-subtitle font-alt" style="margin: 0 0 20px">June ???, 2020 </h3>
              </div>
            </div>
          </div>
        </section>
        <!-- <div class="alert alert-danger" role="alert" style="margin-bottom: 0px">
          <button class="close" type="button" data-dismiss="alert" aria-hidden="true">&times;</button><center><i class="fa fa-cog fa-spin"></i><strong>Alert!</strong> Don't forget to check the <a style="color: #337ab7; text-decoration: underline" href="submissions.html#changelog">latest changes</a> to the challenge's files and rules. <b>Last update: 04/02/2018</b></center>
        </div> -->

        <section>
          <div class='container' style="padding: 30px 0;">
            <h2 class="work-details-title font-alt" style="padding-bottom: 20px">Workshop program</h2>
            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Chairs' opening remarks</h4>
                  <!-- <div class="menu-detail font-serif"><a style="color: #337ab7; text-decoration: underline" href="program18.html#boehnen">Christopher Boehnen (IARPA)</a></div> -->
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">8:30</h4>
                </div>
              </div>
            </div>            

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Invited talk I</h4>
                  <div class="menu-detail font-serif">??? (???) <!-- <br>[<a href="https://goo.gl/53nnTw" target="_blank" style="color: #337ab7; text-decoration: underline">Slides</a>] --></div>
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">8:45</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Track 1 Introduction: Object Detection in Poor Visibility Environments</h4>
                  <!-- <div class="menu-detail font-serif"><a style="color: #337ab7; text-decoration: underline" href="program18.html#hoogs">Anthony Hoogs (Kitware)</a></div> -->
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">9:05</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Track 1 Winners' Oral Presentation</h4>
                  <!-- <div class="menu-detail font-serif">Scott McCloskey (Honeywell) <br>[<a href="https://tinyurl.com/HoneywellACSTUG2" target="_blank" style="color: #337ab7; text-decoration: underline">Slides</a>]
                  </div>   --> 
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">09:30</h4>
                </div>
              </div>
            </div>


            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Coffee break and Poster Session</h4>
                  <div class="menu-detail font-serif">???</div>
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">10:30</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Invited talk II</h4>
                  <div class="menu-detail font-serif">??? (???) <!-- <br>[<a href="https://goo.gl/Y3mDHq" target="_blank" style="color: #337ab7; text-decoration: underline">Slides</a>] --></div>
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">11:15</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Lunch Break</h4>                              
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">12:00</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">
                    <a data-toggle="collapse" data-parent="#accordion" href="#support1">Invited talk III: Intelligent Scene Perception at the Edge <i class="fas fa-sort-down"></i></a>                  
                  </h4>
                  <div class="menu-detail font-serif">??? (???) <!-- <br>[<a href="https://tinyurl.com/HoneywellACSTUG2" target="_blank" style="color: #337ab7; text-decoration: underline">Slides</a>] -->
                  </div>   
                  <div class="panel-collapse collapse" id="support1">
                      <div class="panel-body">????? Rapidly understanding a dynamically changing battle space for real-time situational awareness at the edge requires the use of advanced inference and reasoning models on distributed low-SWaP heterogeneous platforms, such as unmanned aerial and ground vehicles (UAV & UGV) with onboard processing capability. To achieve the goal of realizing automated multi-domain scene understanding and subsequent real-time decision making, we have been developing various types of AI-inspired machine learning algorithms that can potentially provide advanced solutions to key aspects of scene understanding: onboard object detection on both UAVs and UGVs, action/activity and event recognition by processing video streams from UAVs/UGVs as well as surveillance cameras, advanced open set recognition approaches for inferencing human-object interactions in real world settings, and distributed inference models distributed over local edges of a resource-constrained sensor network. In this talk, I will present an overview of the current status of some of the abovementioned projects in the Image Processing branch at the Army Research Laboratory.
                      </div>
                    </div>
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">14:00</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Invited talk IV</h4>
                  <div class="menu-detail font-serif">??? (???) <!-- <br>[<a href="https://tinyurl.com/HoneywellACSTUG2" target="_blank" style="color: #337ab7; text-decoration: underline">Slides</a>] -->
                  </div> 
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">14:45</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Spotlight paper presentations</h4>
                  <!-- <div class="menu-detail font-serif">Walter Scheirer, Sreya Banerjee, Rosaura Vidal Mata (University of Notre Dame)</div> -->
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">15:30</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Track 2 Introduction: Face Verification on FlatCam Images</h4>
                  <!-- <div class="menu-detail font-serif"><a style="color: #337ab7; text-decoration: underline" href="program18.html#hoogs">Anthony Hoogs (Kitware)</a></div> -->
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">16:00</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Track 2 Winners' Oral Presentation</h4>
                  <!-- <div class="menu-detail font-serif">Scott McCloskey (Honeywell) <br>[<a href="https://tinyurl.com/HoneywellACSTUG2" target="_blank" style="color: #337ab7; text-decoration: underline">Slides</a>]
                  </div>   --> 
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">16:30</h4>
                </div>
              </div>
            </div>



            
            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Invited Talk V</h4>
                  <div class="menu-detail font-serif">??? (???)</div>
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">17:50</h4>
                </div>
              </div>
            </div>

            <div class="menu">
              <div class="row">
                <div class="col-sm-8">
                  <h4 class="menu-title font-alt">Award ceremony and concluding remarks</h4>
                  <!-- <div class="menu-detail font-serif">Walter Scheirer, Sreya Banerjee, Rosaura Vidal Mata (University of Notre Dame)</div> -->
                </div>
                <div class="col-sm-4 menu-price-detail">
                  <h4 class="menu-price font-alt">18:00</h4>
                </div>
              </div>
            </div>


          </div>
        </section>

        <section class="module bg-dark-30 parallax-bg restaurant-menu-bg" data-background="assets/images/keynotebg.jpg">
          <div class="container">
            <!-- <div class="row">
              <div class="col-sm-2 col-sm-offset-5">
                <div class="alt-module-subtitle"><span class="holder-w"></span>
                  <h5 class="font-serif">About</h5><span class="holder-w"></span>
                </div>
              </div>
            </div> -->
            <div class="row">
              <div class="col-sm-8 col-sm-offset-2">
                <h2 class="module-title font-alt mb-0">Keynote Speakers</h2>
              </div>
            </div>
          </div>
        </section>

        <!-- <section class="module" style="padding: 30px 0; margin-top: 50px" id="Chellappa">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">                
                <h3 class="work-details-title font-alt"">Al Bovik</h3>
                <h5 class="work-details-title font-alt">University of Texas at Austin</h5>
                <img src="assets/images/bovik.png"/>
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Prof. Al Bovik holds the Cockrell Family Endowed Regents Chair in Engineering at The University of Texas at Austin, where he is Director of the Laboratory for Image and Video Engineering (LIVE). He is a faculty member in the Department of Electrical and Computer Engineering and the Institute for Neuroscience. His research interests include image and video processing, digital television and digital cinema, computational vision, and visual perception. He has published more than 800 technical articles in these areas and holds several U.S. patents. His publications have been cited more than 60,000 times in the literature, his current H-index is above 90, and he is listed as a Highly-Cited Researcher by Thompson Reuters. His several books include the companion volumes The Essential Guides to Image and Video Processing (Academic Press, 2009). </p>
                  <p>Dr. Bovik received the 2017 Edwin H. Land Medal from The Optical Society and the Society for Imaging Science and Technology. Dr. Bovik also received Television’s highest honor, a Primetime Emmy Award for Outstanding Achievement in Engineering Development from the Academy of Television Arts and Sciences (The Television Academy) in October 2015, for his work on the development of video quality prediction models which have become standard tools in broadcast and post-production houses throughout the television industry. He received the IEEE Third Millennium Medal in 2000.</p>
                  <div class="team-social"><a href="http://www.ece.utexas.edu/people/faculty/alan-bovi"><i class="fas fa-globe"></i></a><a href="https://scholar.google.com/citations?user=p-PC50wAAAAJ&hl=en&oi=ao"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section> -->
        <!-- <section class="module" style="padding: 30px 0;" id="Ericson">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Gang Hua</h3>
                <h5 class="work-details-title font-alt">VP & Chief Scientist, Wormpex AI Research</h5>
                <img src="assets/images/ghua.jpg"/ style="width: 80%">
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Gang Hua is the Vice President and Chief Scientist of Wormpex AI Research. His research focuses on computer vision, pattern recognition, machine learning, robotics, towards general Artificial Intelligence, with primary applications in cloud and edge intelligence, and currently with a focus on new retail intelligence. Before that, he served in various roles at Microsoft (2015-18) as the Science/Technical Adviser to the CVP of the Computer Vision Group, Director of Computer Vision Science Team in Redmond and Taipei ATL, and Principal Researcher/Research Manager at Microsoft Research . He was an Associate Professor at Stevens Institute of Technology (2011-15). During 2014-15, he took an on leave and worked on the Amazon-Go project. He was a Visiting Researcher (2011-14) and a Research Staff Member (2010-11) at IBM Research T. J. Watson Center, a Senior Researcher (2009-10) at Nokia Research Center Hollywood, and a Scientist (2006-09) at Microsoft Live labs Research.</p>
                  <p>Dr. Gang Hua is an IEEE Fellow, an IAPR Fellow, and an ACM Distinguished Scientist. He is the recipient of the 2015 IAPR Young Biometrics Investigator Award. He has published more than 150 peer reviewed papers in top conferences and journals. To date, he holds 19 US patents and has 15 more patents pending. He was the program chair of CVPR 2019.</p>
                  <div class="team-social"><a href="https://www.ganghua.org/"><i class="fas fa-globe"></i></a><a href="https://scholar.google.com/citations?user=7SgUlggAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section> -->
        <!-- <section class="module" style="padding: 30px 0;" id="Kwon">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Heesung Kwon</h3>
                <h5 class="work-details-title font-alt">U.S. Army Research Laboratory (ARL)</h5>
                <img src="assets/images/kwon.jpg"/>
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Heesung Kwon is a Senior Researcher and the Image Analytics Team lead at the U.S. Army Research Laboratory (ARL). He received the B.Sc. degree in Electronic Engineering from Sogang University, Seoul, Korea, in 1984, and the MS and Ph.D. degrees in Electrical Engineering from the State University of New York at Buffalo in 1995 and 1999, respectively. From 1983 to 1993, he was with Samsung Electronics Corp., where he worked as a senior research engineer. He was with ARL, Adelphi, MD from 1996 to 2006 working on automatic target detection and hyperspectral signal processing applications. From 2006 to 2007, he was with Johns Hopkins University Applied Physics Laboratory (JHU/APL) working on biological standoff detection problems. Dr. Kwon rejoined ARL in August, 2007 as a team lead, and has been leading image/video analytics efforts pertaining to Un-manned Aerial Systems (UAS), human-autonomy interaction, hyperspectral signal processing, object detection/classification, action/activity recognition, semantic scene understanding, etc. primarily leveraging machine learning and deep learning based approaches. </p>
                  <p>Dr. Heesung Kwon will serve as one of government leads of a ARL sponsored multi-year research program, called Internet of Battlefield Things (IoBT). Dr. Kwon is currently an Associate Editor of IEEE Trans. on Aerospace and Electronic Systems. He also served as Lead Guest Editor of the Special Issue on Algorithms for Multispectral and Hyperspectral Image Analysis of the Journal of Electrical and Computer Engineering. He has published over 100 journal papers, book chapters, and conference papers on these topics. Dr. Kwon is a co-recipient of the best paper award at the Army Science Conference in 2004 and the best paper runner-up award at the IEEE International Conference on Biometrics: Theory, Applications, and Systems (BTAS 2016). He has been on Technical Program Committee for various conferences and workshops relevant to image/video analytics.</p>
                  <div class="team-social"><a href="https://scholar.google.com/citations?user=ayph-mwAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section> -->
        <!-- <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Manmohan Chandraker</h3>
                <h5 class="work-details-title font-alt">NEC Labs America</h5>
                <img src="assets/images/chandraker.jpg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Manmohan Chandraker is an Assistant Professor at the CSE department of the University of California, San Diego and is the Computer Vision Lead at NEC Labs America. He received a PhD from UCSD and was a postdoctoral scholar at UC Berkeley. His research interests are in computer vision, machine learning and graphics-based vision, with applications to autonomous driving and human-computer interfaces. </p>
                  <p>Dr. Manmohan Chandraker's on 3D reconstruction have received the Marr Prize Honorable Mention for Best Paper at ICCV 2007, the 2009 CSE Dissertation Award for Best Thesis at UCSD, a PAMI special issue on best papers of CVPR 2011, the Best Paper Award at CVPR 2014, the 2018 NSF CAREER Award and the 2018 Google Daydream Research Award. He has served as an Area Chair at CVPR, ICCV, ICVGIP and AAAI, associate editor at JAIR, senior PC member at IJCAI and tutorials chair at 3DV.</p>
                  <div class="team-social"><a href="http://cseweb.ucsd.edu/~mkchandraker/"><i class="fa fa-globe"></i></a><a href="https://scholar.google.com/citations?user=oPFCNk4AAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section> -->
        <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Xiaoming Liu</h3>
                <h5 class="work-details-title font-alt">Michigan State University</h5>
                <img src="assets/images/xliu.jpg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Xiaoming Liu earned his Ph.D degree in Electrical and Computer Engineering from Carnegie Mellon University in 2004. He received a B.E. degree from Beijing Information Technology Institute, China and a M.E. degree from Zhejiang University, China in 1997 and 2000 respectively, both in Computer Science. Prior to joining MSU, he was a research scientist at the Computer Vision Laboratory of GE Global Research. His research interests include computer vision, pattern recognition, machine learning, biometrics, human computer interface, etc.</p>
                  <!-- <p></p> -->
                  <div class="team-social"><a href="https://www.cse.msu.edu/~liuxm/index2.html"><i class="fa fa-globe"></i></a><a href="https://scholar.google.com/citations?user=Bii0w1oAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section>
        <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Dengxin Dai</h3>
                <h5 class="work-details-title font-alt">ETH Zurich</h5>
                <img src="assets/images/ddai.jpeg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Dengxin Dai is a Lecturer working with the ​​Computer Vision Lab at ETH Zurich. He is leading the research group TRACE-Zurich working on Autonomous Driving within the R&D project "TRACE: Toyota Research on Automated Cars in Europe". In 2016, he obtained his PhD at ETH Zurich under the supervision of Prof. Luc Van Gool and Prof. Gerhard Schmitt. During the PhD study, he was working on the project VarCity for City Modeling based on camera data.</p>
                  <p>Dr. Dengxin Dai organized the CVPR'19 workshop Vision for All Seasons: Bad Weather and Nighttime, and the ICCV'19 workshop Autonomous Driving. He is a guest editor for the IJCV special issue "Vision for All Seasons" and is an area chair for WACV 2020. He has been a program committee member of several major computer vision conferences and received multiple outstanding reviewer awards. His current research interests include (1) Robust Road Scene Understanding; (2) Learning Driving Models; (3) Human-Vehicle Communication; (4) Sensor Fusion; and (5) Multi-Task Neural Networks.</p>
                  <div class="team-social"><a href="http://www.vision.ee.ethz.ch/~daid/"><i class="fa fa-globe"></i></a><a href="https://scholar.google.co.uk/citations?user=T51W57YAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section>
        <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Vishal M. Patel</h3>
                <h5 class="work-details-title font-alt">Johns Hopkins University</h5>
                <img src="assets/images/vpatel.jpg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Vishal M. Patel is an Assistant Professor in the Department of Electrical and Computer Engineering (ECE) at Johns Hopkins University. Prior to joining Hopkins, he was an A. Walter Tyson Assistant Professor in the Department of ECE at Rutgers University and a member of the research faculty at the University of Maryland Institute for Advanced Computer Studies (UMIACS). He completed his Ph.D. in Electrical Engineering from the University of Maryland, College Park, MD, in 2010.</p>
                  <p>Dr. Vishal M. Patel has received a number of awards including the 2016 ONR Young Investigator Award, the 2016 Jimmy Lin Award for Invention, A. Walter Tyson Assistant Professorship Award, Best Paper Award at IEEE AVSS 2017, Best Paper Award at IEEE BTAS 2015, Honorable Mention Paper Award at IAPR ICB 2018, two Best Student Paper Awards at IAPR ICPR 2018, and Best Poster Awards at BTAS 2015 and 2016. He is an Associate Editor of the IEEE Signal Processing Magazine, IEEE Biometrics Compendium, and serves on the Information Forensics and Security Technical Committee of the IEEE Signal Processing Society. He is a member of Eta Kappa Nu, Pi Mu Epsilon, and Phi Beta Kappa.</p>
                  <div class="team-social"><a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/"><i class="fa fa-globe"></i></a><a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section>
        <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Bihan Wen</h3>
                <h5 class="work-details-title font-alt">Nanyang Technological University (NTU), Singapore</h5>
                <img src="assets/images/bwen.jpg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Bihan Wen received the B. Eng. degree in Electrical and Electronic Engineering (EEE) from Nanyang Technological University (NTU), Singapore, in 2012, the MS and PhD degrees in Electrical and Computer Engineering from University of Illinois at Urbana-Champaign (UIUC), USA, in 2015 and 2018, respectively.</p>
                  <!-- <p></p> -->
                  <div class="team-social"><a href="http://bihanwen.ece.illinois.edu/"><i class="fa fa-globe"></i></a><a href="https://scholar.google.com/citations?user=ypkClpwAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section>
        <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Zhiding Yu</h3>
                <h5 class="work-details-title font-alt">NVIDIA</h5>
                <img src="assets/images/zyu.jpg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Zhiding Yu joined NVIDIA Research as a Research Scientist in 2018. Before that, he obtained Ph.D. in ECE from Carnegie Mellon University in 2017, and M.Phil. in ECE from The Hong Kong University of Science and Technology in 2012. His current research interests mainly focus on deep representation learning, weakly/semi-supervised learning, transfer learning and structured prediction, with their applications to semantic/instance segmentation, object detection, boundary detection and domain adaptation/generalization etc.</p>
                  <p>Dr. Zhiding Yu is a winner of the Domain Adaptation for Semantic Segmentation Challenge in Workshop on Autonomous Driving (WAD) at CVPR18. He is a co-author of the best student paper at ISCSLP14, and winner of the best paper award at WACV15. He was twice awarded the HKTIIT Post-Graduate Excellence Scholarships in 2010 and 2012. His intern work on deep facial expression recognition at Microsoft Research won first runner-up at the EmotiW-SFEW Challenge 2015 and was integrated into the Microsoft Emotion Recognition API under the Microsoft Azure Cognitive Services.</p>
                  <div class="team-social"><a href="https://chrisding.github.io/"><i class="fa fa-globe"></i></a><a href="https://scholar.google.com/citations?user=1VI_oYUAAAAJ&hl=en"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section>
        <section class="module" style="padding: 30px 0;" id="Chandraker">
          <div class="container">
            <div class="row">
              <div class="col-sm-4 col-md-4 col-lg-4" style="text-align: right">
                <h3 class="work-details-title font-alt">Xi Yin</h3>
                <h5 class="work-details-title font-alt">Microsoft Cloud and AI</h5>
                <img src="assets/images/xyin.jpg" style="width: 70%" />
              </div>
              <div class="col-sm-8 col-md-8 col-lg-8">
                <div class="work-details" style="text-align: justify">                  
                  <p>Dr. Xi Yin an Applied Scientist in the Computer Vision team at Microsoft Cloud and AI since Sep. 2018. She got her Ph.D. from the Department of Computer Science and Engineering at Michigan State University, where she was a member of the Computer Vision Lab lead by Professor Xiaoming Liu. In 2013, she graduated with a Bachelor’s degree in Electrical Engineering from Wuhan University.</p>
                  <p>Dr. Xi Yin's research interests lie in computer vision and deep learning. Specifically, Dr. Xi Yin is interested in Large-Scale Object Detection, Weakly-Supervised Learning, Face Recognition, Face Generation, Representation Learning and Transfer Learning.</p>
                  <div class="team-social"><a href="https://xiyinmsu.github.io/"><i class="fa fa-globe"></i></a><a href="https://scholar.google.com/citations?user=FAEzhskAAAAJ"><i class="fab fa-google"></i></a></div>
                </div>
              </div>
            </div>
          </div>
        </section>
      <a id="ddfooterLink" href="footer.html">Footer</a>
      <div class="scroll-up"><a href="#totop"><i class="fa fa-angle-double-up"></i></a></div>
    </main>
    <!--  
    JavaScripts
    =============================================
    -->
    <script src="assets/lib/jquery/dist/jquery.js"></script>
    <script src="assets/lib/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="assets/lib/wow/dist/wow.js"></script>
    <script src="assets/lib/jquery.mb.ytplayer/dist/jquery.mb.YTPlayer.js"></script>
    <script src="assets/lib/isotope/dist/isotope.pkgd.js"></script>
    <script src="assets/lib/imagesloaded/imagesloaded.pkgd.js"></script>
    <!-- <script src="assets/lib/flexslider/jquery.flexslider.js"></script> -->
    <script src="assets/lib/owl.carousel/dist/owl.carousel.min.js"></script>
    <!-- <script src="assets/lib/smoothscroll.js"></script> -->
    <script src="assets/lib/magnific-popup/dist/jquery.magnific-popup.js"></script>
    <script src="assets/lib/simple-text-rotator/jquery.simple-text-rotator.min.js"></script>
    <script src="assets/js/plugins.js"></script>
    <script src="assets/js/main.js"></script>
    <script src="assets/js/ddmenu.js" type="text/javascript"></script>
    <script src="assets/js/ddfooter.js" type="text/javascript"></script>
</body>
</html>